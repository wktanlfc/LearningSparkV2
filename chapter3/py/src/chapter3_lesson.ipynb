{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, try to find the environments before running\n",
      "/Users/kiang/Desktop/PythonProjects/Repos/ApacheSparkLearning/LearningSparkV2/chapter3/py/src\n",
      "/Users/kiang/Desktop/PythonProjects/Repos/ApacheSparkLearning/sparklearning_env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "echo Hello, try to find the environments before running\n",
    "echo $(pwd)\n",
    "echo $VIRTUAL_ENV\n",
    "echo $SPARK_HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The *DataFrame* API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StructTypes are a Seq of Struct Fields. 2 Names with the same name are not allowed.\n",
    "https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "\n",
    "ArrayType(elementType, containsNull): Represents values comprising a sequence of elements with the type of elementType. containsNull is used to indicate if elements in a ArrayType value can have null values.\n",
    "\n",
    "MapType(keyType, valueType, valueContainsNull): Represents values comprising a set of key-value pairs. The data type of keys is described by keyType and the data type of values is described by valueType. For a MapType value, keys are not allowed to have null values. valueContainsNull is used to indicate if values of a MapType value can have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/16 20:19:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"Aggregations and Computations in Spark Exercise - Chapter 3\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_fire_datasets = \"/Users/kiang/Desktop/PythonProjects/Repos/ApacheSparkLearning/LearningSparkV2/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StructType Parameter with a List of StructField() methods per column.\n",
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "              StructField('UnitID', StringType(), True),\n",
    "              StructField('IncidentNumber', IntegerType(), True),\n",
    "              StructField('CallType', StringType(), True),\n",
    "              StructField('CallDate', StringType(), True),\n",
    "              StructField('WatchDate', StringType(), True),\n",
    "              StructField('CallFinalDisposition', StringType(), True),\n",
    "              StructField('AvailableDtTm', StringType(), True),\n",
    "              StructField('Address', StringType(), True),\n",
    "              StructField('City', StringType(), True),\n",
    "              StructField('Zipcode', IntegerType(), True),\n",
    "              StructField('Battalion', StringType(), True),\n",
    "              StructField('StationArea', StringType(), True),\n",
    "              StructField('Box', StringType(), True),\n",
    "              StructField('OriginalPriority', StringType(), True),\n",
    "              StructField('Priority', StringType(), True),\n",
    "              StructField('FinalPriority', IntegerType(), True),\n",
    "              StructField('ALSUnit', BooleanType(), True),\n",
    "              StructField('CallTypeGroup', StringType(), True),\n",
    "              StructField('NumAlarms', IntegerType(), True),\n",
    "              StructField('UnitType', StringType(), True),\n",
    "              StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "              StructField('FirePreventionDistrict', StringType(), True),\n",
    "              StructField('SupervisorDistrict', StringType(), True),\n",
    "              StructField('Neighborhood', StringType(), True),\n",
    "              StructField('Location', StringType(), True),\n",
    "              StructField('RowID', StringType(), True),\n",
    "              StructField('Delay', FloatType(), True)])\n",
    "\n",
    "# Using the DataFrameReader Interface to read the CSV file into Spark.\n",
    "fire_df = spark.read.csv(sf_fire_datasets, header = True, schema = fire_schema)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Columns from spark dataframes\n",
    "\n",
    "> To access columns, use ```.columns```\n",
    "> You can access them individual columnnames by \n",
    "> ```.columns[index]```\n",
    "\n",
    "> Columns are stored as a list, so you can iterate through it.\n",
    "```for col in df.columns```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber\n",
      "UnitID\n",
      "IncidentNumber\n",
      "CallType\n",
      "CallDate\n",
      "WatchDate\n",
      "CallFinalDisposition\n",
      "AvailableDtTm\n",
      "Address\n",
      "City\n",
      "Zipcode\n",
      "Battalion\n",
      "StationArea\n",
      "Box\n",
      "OriginalPriority\n",
      "Priority\n",
      "FinalPriority\n",
      "ALSUnit\n",
      "CallTypeGroup\n",
      "NumAlarms\n",
      "UnitType\n",
      "UnitSequenceInCallDispatch\n",
      "FirePreventionDistrict\n",
      "SupervisorDistrict\n",
      "Neighborhood\n",
      "Location\n",
      "RowID\n",
      "Delay\n"
     ]
    }
   ],
   "source": [
    "fire_df.columns\n",
    "fire_df.columns[0]\n",
    "for col in fire_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/16 20:19:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|      UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|         TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|         CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "|  20110072|   T08|       2003279|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 08:03:...|  BEALE ST/FOLSOM ST|  SF|  94105|      B03|         35|2122|               3|       3|            3|  false|         NULL|        1|         TRUCK|                         2|                     3|                 6|Financial Distric...|(37.7886866619654...|020110072-T08|     1.75|\n",
      "|  20110125|   E33|       2003301|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:46:...|0 Block of FARALL...|  SF|  94112|      B09|         33|8324|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         2|                     9|                11|Oceanview/Merced/...|(37.7140353531157...|020110125-E33|2.7166667|\n",
      "|  20110130|   E36|       2003304|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:58:...|600 Block of POLK ST|  SF|  94102|      B02|         03|3114|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     2|                 6|          Tenderloin|(37.7826266328595...|020110130-E36|1.7833333|\n",
      "|  20110197|   E05|       2003343|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 12:06:...|1500 Block of WEB...|  SF|  94115|      B04|         05|3513|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     4|                 5|           Japantown|(37.784958590666,...|020110197-E05|1.5166667|\n",
      "|  20110215|   E06|       2003348|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 01:08:...|DIAMOND ST/MARKET ST|  SF|  94114|      B05|         06|5415|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     5|                 8| Castro/Upper Market|(37.7618954753708...|020110215-E06|2.7666667|\n",
      "|  20110274|   M07|       2003381|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 03:31:...|2700 Block of MIS...|  SF|  94110|      B06|         11|5525|               1|       1|            2|   true|         NULL|        1|         MEDIC|                         1|                     6|                 9|             Mission|(37.7530339738059...|020110274-M07|2.1833334|\n",
      "|  20110275|   T15|       2003382|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 02:59:...|BRUNSWICK ST/GUTT...|  SF|  94112|      B09|         43|6218|               3|       3|            3|  false|         NULL|        1|         TRUCK|                         1|                     9|                11|           Excelsior|(37.7105545807996...|020110275-T15|      2.5|\n",
      "|  20110304|   E03|       2003399|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:22:...|1000 Block of SUT...|  SF|  94109|      B04|         03|1557|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     4|                 3|            Nob Hill|(37.7881263034393...|020110304-E03|2.4166667|\n",
      "|  20110308|   E14|       2003403|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:18:...|100 Block of 21ST...|  SF|  94121|      B07|         14|7173|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     7|                 1|      Outer Richmond|(37.7850084431077...|020110308-E14|     4.95|\n",
      "|  20110313|   B10|       2003408|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 04:09:...|700 Block of CAPP ST|  SF|  94110|      B06|         07|5472|               3|       3|            3|  false|         NULL|        1|         CHIEF|                         6|                     6|                 9|             Mission|(37.7547064357942...|020110313-B10|1.4166666|\n",
      "|  20110313|    D3|       2003408|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 04:09:...|700 Block of CAPP ST|  SF|  94110|      B06|         07|5472|               3|       3|            3|  false|         NULL|        1|         CHIEF|                         4|                     6|                 9|             Mission|(37.7547064357942...| 020110313-D3|2.5333333|\n",
      "|  20110313|   E32|       2003408|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 04:09:...|700 Block of CAPP ST|  SF|  94110|      B06|         07|5472|               3|       3|            3|   true|         NULL|        1|        ENGINE|                         8|                     6|                 9|             Mission|(37.7547064357942...|020110313-E32|1.8833333|\n",
      "|  20110315|   RC2|       2003409|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:34:...|200 Block of LAGU...|  SF|  94116|      B08|         20|8635|               3|       3|            3|   true|         NULL|        1|RESCUE CAPTAIN|                         2|                     8|                 7|  West of Twin Peaks|(37.7501117393668...|020110315-RC2|     5.35|\n",
      "|  20110330|   E14|       2003417|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:51:...|BALBOA ST/PARK PR...|  SF|  94118|      B07|         31|7145|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                     7|                 1|      Inner Richmond|(37.7768682293368...|020110330-E14|      2.0|\n",
      "|  20110330|   M12|       2003417|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:51:...|BALBOA ST/PARK PR...|  SF|  94118|      B07|         31|7145|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         2|                     7|                 1|      Inner Richmond|(37.7768682293368...|020110330-M12|1.8166667|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()\n",
    "# fire_df.createOrReplaceTempView(\"temp_tbl\")\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "        #   select * from temp_tbl limit 100\n",
    "        #   \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+\n",
      "|CallNumber|UnitID|IncidentNumber|\n",
      "+----------+------+--------------+\n",
      "|20110016  |T13   |2003235       |\n",
      "|20110022  |M17   |2003241       |\n",
      "|20110023  |M41   |2003242       |\n",
      "|20110032  |E11   |2003250       |\n",
      "|20110043  |B04   |2003259       |\n",
      "+----------+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m fire_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnitID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncidentNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m, truncate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#?GROUP BY, ORDER BY, SELECT, WHERE: Count the number of rows that are in each unique call type.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m (fire_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m             \u001b[38;5;241m.\u001b[39mwhere(\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCallType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39misNotNull()) \u001b[38;5;66;03m#*Is this step needed, does spark innately possess the ability to remove rows with null values?\u001b[39;00m\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;241m.\u001b[39mshow(truncate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     13\u001b[0m (fire_df\u001b[38;5;241m.\u001b[39mcount())\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/16 20:19:56 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "#?SELECT\n",
    "fire_df.select(\"CallNumber\", \"UnitID\", \"IncidentNumber\").show(5, truncate = False )\n",
    "\n",
    "#?GROUP BY, ORDER BY, SELECT, WHERE: Count the number of rows that are in each unique call type.\n",
    "(fire_df.select(\"CallType\")\n",
    "            .where(col(\"CallType\").isNotNull()) #*Is this step needed, does spark innately possess the ability to remove rows with null values?\n",
    "            .groupBy(\"CallType\")\n",
    "            .count()\n",
    "            .orderBy('count', ascending = False)\n",
    "            .show(truncate = False)\n",
    "        )\n",
    "\n",
    "(fire_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas in Spark Dataframes\n",
    "\n",
    "### There are some benefits of declaring a schema early before reading in datasource. (Schema on Read)\n",
    "\n",
    "> * You relieve Spark from the onus of inferring data types.\n",
    "> \n",
    "> * You prevent spark from creating a separate job just to read a large portion of your file to ascertain the schema, which for a large data file can be expensive and time consuming.\n",
    "> \n",
    "> * You can detect errors early if data doesn't match the schema.\n",
    "\n",
    "\n",
    "### Two ways to define a Schema\n",
    "> Spark allows you to define a schema in two ways. \n",
    "> * One is to define it programmatially, \n",
    "> \n",
    "> * The other is to employ a Data Definition Language (DDL) string, which is much simpler and easier to read.\n",
    "\n",
    "\n",
    "To define a schema programmatically for a DataFrame with three named columns, author, title, and pages, you can use the Spark DataFrame API. \n",
    "\n",
    "For example:\n",
    "\n",
    "In Scala\n",
    "```\n",
    "import org.apache.spark.sql.types._\n",
    "val schema = StructType(Array(\n",
    "                        StructField(\"author\", StringType, false),\n",
    "                        StructField(\"title\", StringType, false), \n",
    "                        StructField(\"pages\", IntegerType, false)\n",
    "                        ))\n",
    "```\n",
    "In Python\n",
    "\n",
    "```\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    "      StructField(\"title\", StringType(), False),\n",
    "      StructField(\"pages\", IntegerType(), False)])\n",
    "```\n",
    "\n",
    "Defining the same schema using DDL is much simpler:\n",
    "\n",
    "In Scala:\n",
    "```\n",
    "val schema = \"author STRING, title STRING, pages INT\"\n",
    "```\n",
    "\n",
    "Python\n",
    "```\n",
    "schema = \"author STRING, title STRING, pages INT\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import org.apache.spark.sql.types#\n",
    "\n",
    "Read up on this to get more information on how to use spark types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/16 17:41:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "|  20110072|   T08|       2003279|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 08:03:...|  BEALE ST/FOLSOM ST|  SF|  94105|      B03|         35|2122|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     3|                 6|Financial Distric...|(37.7886866619654...|020110072-T08|     1.75|\n",
      "|  20110125|   E33|       2003301|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:46:...|0 Block of FARALL...|  SF|  94112|      B09|         33|8324|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         2|                     9|                11|Oceanview/Merced/...|(37.7140353531157...|020110125-E33|2.7166667|\n",
      "|  20110130|   E36|       2003304|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:58:...|600 Block of POLK ST|  SF|  94102|      B02|         03|3114|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     2|                 6|          Tenderloin|(37.7826266328595...|020110130-E36|1.7833333|\n",
      "|  20110197|   E05|       2003343|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 12:06:...|1500 Block of WEB...|  SF|  94115|      B04|         05|3513|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     4|                 5|           Japantown|(37.784958590666,...|020110197-E05|1.5166667|\n",
      "|  20110215|   E06|       2003348|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 01:08:...|DIAMOND ST/MARKET ST|  SF|  94114|      B05|         06|5415|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     5|                 8| Castro/Upper Market|(37.7618954753708...|020110215-E06|2.7666667|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df.select(\n",
    "                 \"CallNumber\"\n",
    "                ,\"UnitID\"\n",
    "                ,\"IncidentNumber\"\n",
    "                ,\"CallType\"\n",
    "                ,\"CallDate\"\n",
    "                ,\"WatchDate\"\n",
    "                ,\"CallFinalDisposition\"\n",
    "                ,\"AvailableDtTm\"\n",
    "                ,\"Address\"\n",
    "                ,\"City\"\n",
    "                ,\"Zipcode\"\n",
    "                ,\"Battalion\"\n",
    "                ,\"StationArea\"\n",
    "                ,\"Box\"\n",
    "                ,\"OriginalPriority\"\n",
    "                ,\"Priority\"\n",
    "                ,\"FinalPriority\"\n",
    "                ,\"ALSUnit\"\n",
    "                ,\"CallTypeGroup\"\n",
    "                ,\"NumAlarms\"\n",
    "                ,\"UnitType\"\n",
    "                ,\"UnitSequenceInCallDispatch\"\n",
    "                ,\"FirePreventionDistrict\"\n",
    "                ,\"SupervisorDistrict\"\n",
    "                ,\"Neighborhood\"\n",
    "                ,\"Location\"\n",
    "                ,\"RowID\"\n",
    "                ,\"Delay\"\n",
    "                )\n",
    "                .show(10)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('CallNumber', IntegerType(), True), StructField('UnitID', StringType(), True), StructField('IncidentNumber', IntegerType(), True), StructField('CallType', StringType(), True), StructField('CallDate', StringType(), True), StructField('WatchDate', StringType(), True), StructField('CallFinalDisposition', StringType(), True), StructField('AvailableDtTm', StringType(), True), StructField('Address', StringType(), True), StructField('City', StringType(), True), StructField('Zipcode', IntegerType(), True), StructField('Battalion', StringType(), True), StructField('StationArea', StringType(), True), StructField('Box', StringType(), True), StructField('OriginalPriority', StringType(), True), StructField('Priority', StringType(), True), StructField('FinalPriority', IntegerType(), True), StructField('ALSUnit', BooleanType(), True), StructField('CallTypeGroup', StringType(), True), StructField('NumAlarms', IntegerType(), True), StructField('UnitType', StringType(), True), StructField('UnitSequenceInCallDispatch', IntegerType(), True), StructField('FirePreventionDistrict', StringType(), True), StructField('SupervisorDistrict', StringType(), True), StructField('Neighborhood', StringType(), True), StructField('Location', StringType(), True), StructField('RowID', StringType(), True), StructField('Delay', FloatType(), True)])\n",
      "StructField('UnitID', StringType(), True)\n",
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Use .schema to retrieve the DDL from the declared df, if you want to reuse it.\n",
    "print(fire_df.schema)\n",
    "\n",
    "# Retrieve the inside of the field\n",
    "print(fire_df.schema['UnitID'])\n",
    "\n",
    "#Use this \n",
    "print(fire_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from JSON Files \n",
    "\n",
    "You can read the data from the json files too.\n",
    "Try to read in the blogs.json file in the ./databricks-datasets\n",
    "\n",
    "Note : blogs.json used here is not a typical JSON file. You'll likely run into problems when running with actual json files.\n",
    "https://spark.apache.org/docs/latest/sql-data-sources-json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "|           Campaigns|    First| Hits| Id|   Last|Published|              Url|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "| [twitter, LinkedIn]|    Jules| 4535|  1|  Damji| 1/4/2016|https://tinyurl.1|\n",
      "| [twitter, LinkedIn]|   Brooke| 8908|  2|  Wenig| 5/5/2018|https://tinyurl.2|\n",
      "|[web, twitter, FB...|    Denny| 7659|  3|    Lee| 6/7/2019|https://tinyurl.3|\n",
      "|       [twitter, FB]|Tathagata|10568|  4|    Das|5/12/2018|https://tinyurl.4|\n",
      "|[web, twitter, FB...|    Matei|40578|  5|Zaharia|5/14/2014|https://tinyurl.5|\n",
      "| [twitter, LinkedIn]|  Reynold|25568|  6|    Xin| 3/2/2015|https://tinyurl.6|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_path  = \"/Users/kiang/Desktop/PythonProjects/Repos/ApacheSparkLearning/LearningSparkV2/databricks-datasets/learning-spark-v2/blogs.json\"\n",
    "\n",
    "# Without defining, its schema on read.\n",
    "blogs_df = spark.read.json(blogs_path)\n",
    "\n",
    "blogs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns and Expressions (Page. 54)\n",
    "\n",
    "You can also use logical or mathematical expressions on columns.\n",
    "\n",
    "You could create using\n",
    "```expr(\"columnName  * 5\")``` or \n",
    "```(expr(\"columnName1 - 5\") > col(\"columnName\"))```\n",
    "where colname is a spark type.\n",
    "\n",
    "\n",
    "```expr()``` is a part of the pyspark.sql.functions (python) and org.apache.spark.sql.functions (Scala) packages\n",
    "\n",
    "Note: Where do you use the expr() function? \n",
    "* You can use it inside the ```.select()``` statement i.e. ```df.select(expr())```. It will compute values base on the expression.\n",
    "* Or you could use it inside the ```.where()``` i.e ```df.select().where(expr())``` statement.\n",
    "* You can also use it within the ```.withColumn(\"Name\" , expr(\"ColumnName * 2\"))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+---+-------+---------+-----------------+---------------+----------+\n",
      "|           Campaigns|    First| Hits| Id|   Last|Published|              Url|(First = Jules)|(Hits * 2)|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+---------------+----------+\n",
      "| [twitter, LinkedIn]|    Jules| 4535|  1|  Damji| 1/4/2016|https://tinyurl.1|           true|      9070|\n",
      "| [twitter, LinkedIn]|   Brooke| 8908|  2|  Wenig| 5/5/2018|https://tinyurl.2|          false|     17816|\n",
      "|[web, twitter, FB...|    Denny| 7659|  3|    Lee| 6/7/2019|https://tinyurl.3|          false|     15318|\n",
      "|       [twitter, FB]|Tathagata|10568|  4|    Das|5/12/2018|https://tinyurl.4|          false|     21136|\n",
      "|[web, twitter, FB...|    Matei|40578|  5|Zaharia|5/14/2014|https://tinyurl.5|          false|     81156|\n",
      "| [twitter, LinkedIn]|  Reynold|25568|  6|    Xin| 3/2/2015|https://tinyurl.6|          false|     51136|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adds a boolean row.\n",
    "(blogs_df.select('*'\n",
    "                 ,expr(\"First == 'Jules'\")\n",
    "                 ,expr(\"Hits * 2\")\n",
    "                 ).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use expression to filter a value.\n",
    "blogs_df.select('*').where(expr(\"First == 'Jules'\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blogs_df.printSchema())\n",
    "\n",
    "# Notice Publish is a string. Because this table is schema on Read, spark inferred Published wrong, thus, order by will not work\n",
    "# correctly on strings.\n",
    "(blogs_df\n",
    " .withColumn('FullName', concat(expr(\"First\") , expr(\"Last\"))) # Used in withColumn\n",
    " .select('*')\n",
    " .orderBy(\"Hits\")\n",
    " ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note:\n",
    "\n",
    "> Column Objects in a Dataframe cannot exist in isolation (i.e. $\"FullName\") each column is a part of a row in a record and all the rows together constitute a Dataframe, which was we will learn later in the chapter,\n",
    "> is really a Dataset[Row] in Scala.\n",
    ">\n",
    "> Next Pg 57. on Rows*** Code in Scala.\n",
    "\n",
    "Will continue on to Dataframe Operations pg 58."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Dataframe Operations \n",
    "\n",
    "Reading in a Large CSV file from `sf-fire-calls.csv`\n",
    "You can use DataFrameReader and DataFrameWriter and its *methods* to read and write a bunch of formats.\n",
    "* Avro\n",
    "* JSON\n",
    "* CSV\n",
    "* Parquet - A columnar format that uses snappy compression to compress the data.\n",
    "If the dataframe is written as parquet, it preserves the format as part of the Parquet metadata.\n",
    "* Text\n",
    "* ORC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in dataframes can go wrong with defined schemas! \n",
    "\n",
    " Here i try defining the schema first. The location field looks likes this *(13.3123543245, 13.5456755)*\n",
    "\n",
    "https://stackoverflow.com/questions/71969652/read-csv-that-contains-array-of-string-in-pyspark\n",
    "\n",
    " *CallDate* and *WatchDate* fields both are YYYY/MM/DD formats in the CSV file, but they are not read in properly.\n",
    "\n",
    "\n",
    "\n",
    " *CallType* fields is read in as NULL, means something went wrong.\n",
    " \n",
    " Quickly realise 2 things. first, i cannot define the schema with complex datatypes when reading in a CSV file. You will have to read in complex types as Strings first.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing using DataFrameWriter is as good as `spark.write.format('parquet').save(file_path_to_save_to)`\n",
    "\n",
    "Alternatively, you can save it as a **Table** when you are writing using DataFrameWriters, this registers the metadata in \n",
    "the *Hive metadata store*.\n",
    "`spark.write.format('parquet').saveAsTable(file_path_to_save_to)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_schema = StructType([StructField('CallNumber',IntegerType(),True)\n",
    "                         ,StructField(\"UnitID\",StringType(),True)\n",
    "                         ,StructField(\"IncidentNumber\",StringType(),True)\n",
    "                         ,StructField(\"CallType\",StringType(),True)\n",
    "                         ,StructField(\"CallDate\",DateType(),True)\n",
    "                         ,StructField(\"WatchDate\",DateType(),True)\n",
    "                         ,StructField(\"CallFinalDisposition\",StringType(),True)\n",
    "                         ,StructField(\"AvailableDtTm\",DateType(),True)\n",
    "                         ,StructField(\"Address\",StringType(),True)\n",
    "                         ,StructField(\"City\",StringType(),True)\n",
    "                         ,StructField(\"Zipcode\",StringType(),True)\n",
    "                         ,StructField(\"Battalion\",StringType(),True)\n",
    "                         ,StructField(\"StationArea\",StringType(),True)\n",
    "                         ,StructField(\"Box\",StringType(),True)\n",
    "                         ,StructField(\"OriginalPriority\",IntegerType(),True)\n",
    "                         ,StructField(\"Priority\",IntegerType(),True)\n",
    "                         ,StructField(\"FinalPriority\",IntegerType(),True)\n",
    "                         ,StructField(\"ALSUnit\", StringType(),True)\n",
    "                         ,StructField(\"CallTypeGroup\",StringType(),True)\n",
    "                         ,StructField(\"NumAlarms\",IntegerType(),True)\n",
    "                         ,StructField(\"UnitType\",StringType(),True)\n",
    "                         ,StructField(\"UnitSequenceInCallDispatch\",IntegerType(),True)\n",
    "                         ,StructField(\"FirePreventionDistrict\",IntegerType(),True)\n",
    "                         ,StructField(\"SupervisorDistrict\",IntegerType(),True)\n",
    "                         ,StructField(\"Neighborhood\",StringType() ,True)\n",
    "                        #  ,StructField(\"Location\",ArrayType(DecimalType(), True),True) # Location is a tuple of \n",
    "                         ,StructField(\"Location\", StringType() ,True) # Use this will allow data to read successfully.\n",
    "                         ,StructField(\"RowID\",StringType(),True)\n",
    "                         ,StructField(\"Delay\",DecimalType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_path = \"/Users/kiang/Desktop/PythonProjects/Repos/ApacheSparkLearning/LearningSparkV2/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\"\n",
    "\n",
    "# Reads in by default all strings\n",
    "!# You cannot read in the csv data with a Schema of Complex Types! Read them in as strings first.\n",
    "calls_df = spark.read.format('csv').load(calls_path, header = True, schema = test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+--------+---------+--------------------+-------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate|WatchDate|CallFinalDisposition|AvailableDtTm|Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood         |Location                             |RowID        |Delay|\n",
      "+----------+------+--------------+----------------+--------+---------+--------------------+-------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |NULL    |NULL     |Other               |NULL         |2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |NULL         |1        |TRUCK   |2                         |4                     |5                 |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|3    |\n",
      "|20110022  |M17   |2003241       |Medical Incident|NULL    |NULL     |Other               |NULL         |0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |NULL         |1        |MEDIC   |1                         |10                    |10                |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|5    |\n",
      "|20110023  |M41   |2003242       |Medical Incident|NULL    |NULL     |Other               |NULL         |MARKET ST/MCALLISTER ST    |SF  |94102  |B03      |01         |1455|3               |3       |3            |true   |NULL         |1        |MEDIC   |2                         |3                     |6                 |Tenderloin           |(37.7811772186856, -122.411699931232)|020110023-M41|2    |\n",
      "+----------+------+--------------+----------------+--------+---------+--------------------+-------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls_df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hang on.. these fields **CallDate** **WatchDate** are not reading in correctly...\n",
    "\n",
    "Looks like all of them are NULLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalls_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      2\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnitID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallType\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallDate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWatchDate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallTypeGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwhere(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNotNull())\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "calls_df.select(\"CallNumber\" \n",
    "         ,\"UnitID\"\n",
    "         ,\"CallType\"\n",
    "         ,\"CallDate\"\n",
    "         ,\"WatchDate\"\n",
    "         ,\"CallTypeGroup\").where(col(\"CallDate\").isNotNull()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `f.to_timestamp(<Variable> , 'format')` to change dates into their appropriate format from a String. \n",
    "\n",
    "Note the 2nd Parameter here `format` is the format that the string is in, not the format u want to write it into!\n",
    "\n",
    "I.e. `withColumn(Name, to_timestamp(Name, 'yyyy/mm/dd')`\n",
    "\n",
    "Lets try it again, by reading in the dataset again. This time with all String Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_schema = StructType([StructField('CallNumber',IntegerType(),True)\n",
    "                         ,StructField(\"UnitID\",StringType(),True)\n",
    "                         ,StructField(\"IncidentNumber\",StringType(),True)\n",
    "                         ,StructField(\"CallType\",StringType(),True)\n",
    "                         ,StructField(\"CallDate\",StringType(),True)\n",
    "                         ,StructField(\"WatchDate\",StringType(),True)\n",
    "                         ,StructField(\"CallFinalDisposition\",StringType(),True)\n",
    "                         ,StructField(\"AvailableDtTm\",StringType(),True)\n",
    "                         ,StructField(\"Address\",StringType(),True)\n",
    "                         ,StructField(\"City\",StringType(),True)\n",
    "                         ,StructField(\"Zipcode\",StringType(),True)\n",
    "                         ,StructField(\"Battalion\",StringType(),True)\n",
    "                         ,StructField(\"StationArea\",StringType(),True)\n",
    "                         ,StructField(\"Box\",StringType(),True)\n",
    "                         ,StructField(\"OriginalPriority\",IntegerType(),True)\n",
    "                         ,StructField(\"Priority\",IntegerType(),True)\n",
    "                         ,StructField(\"FinalPriority\",IntegerType(),True)\n",
    "                         ,StructField(\"ALSUnit\", StringType(),True)\n",
    "                         ,StructField(\"CallTypeGroup\",StringType(),True)\n",
    "                         ,StructField(\"NumAlarms\",IntegerType(),True)\n",
    "                         ,StructField(\"UnitType\",StringType(),True)\n",
    "                         ,StructField(\"UnitSequenceInCallDispatch\",IntegerType(),True)\n",
    "                         ,StructField(\"FirePreventionDistrict\",IntegerType(),True)\n",
    "                         ,StructField(\"SupervisorDistrict\",IntegerType(),True)\n",
    "                         ,StructField(\"Neighborhood\",StringType() ,True)\n",
    "                        #  ,StructField(\"Location\",ArrayType(DecimalType(), True),True) # Location is a tuple of \n",
    "                         ,StructField(\"Location\", StringType() ,True) # Location is a tuple of \n",
    "                         ,StructField(\"RowID\",StringType(),True)\n",
    "                         ,StructField(\"Delay\",DecimalType(),True)])\n",
    "calls_df = spark.read.format('csv').load(calls_path, header = True, schema = test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CallNumber=20110016, UnitID='T13', IncidentNumber='2003235', CallType='Structure Fire', CallDate=datetime.datetime(2002, 1, 1, 0, 11), WatchDate=datetime.datetime(2002, 1, 1, 0, 10), CallFinalDisposition='Other', AvailableDtTm='01/11/2002 01:51:44 AM', Address='2000 Block of CALIFORNIA ST', City='SF', Zipcode='94109', Battalion='B04', StationArea='38', Box='3362', OriginalPriority=3, Priority=3, FinalPriority=3, ALSUnit='false', CallTypeGroup=None, NumAlarms=1, UnitType='TRUCK', UnitSequenceInCallDispatch=2, FirePreventionDistrict=4, SupervisorDistrict=5, Neighborhood='Pacific Heights', Location='(37.7895840679362, -122.428071912459)', RowID='020110016-T13', Delay=Decimal('3'), CallDateAsDt=datetime.date(2002, 1, 1)),\n",
       " Row(CallNumber=20110022, UnitID='M17', IncidentNumber='2003241', CallType='Medical Incident', CallDate=datetime.datetime(2002, 1, 1, 0, 11), WatchDate=datetime.datetime(2002, 1, 1, 0, 10), CallFinalDisposition='Other', AvailableDtTm='01/11/2002 03:01:18 AM', Address='0 Block of SILVERVIEW DR', City='SF', Zipcode='94124', Battalion='B10', StationArea='42', Box='6495', OriginalPriority=3, Priority=3, FinalPriority=3, ALSUnit='true', CallTypeGroup=None, NumAlarms=1, UnitType='MEDIC', UnitSequenceInCallDispatch=1, FirePreventionDistrict=10, SupervisorDistrict=10, Neighborhood='Bayview Hunters Point', Location='(37.7337623673897, -122.396113802632)', RowID='020110022-M17', Delay=Decimal('5'), CallDateAsDt=datetime.date(2002, 1, 1)),\n",
       " Row(CallNumber=20110023, UnitID='M41', IncidentNumber='2003242', CallType='Medical Incident', CallDate=datetime.datetime(2002, 1, 1, 0, 11), WatchDate=datetime.datetime(2002, 1, 1, 0, 10), CallFinalDisposition='Other', AvailableDtTm='01/11/2002 02:39:50 AM', Address='MARKET ST/MCALLISTER ST', City='SF', Zipcode='94102', Battalion='B03', StationArea='01', Box='1455', OriginalPriority=3, Priority=3, FinalPriority=3, ALSUnit='true', CallTypeGroup=None, NumAlarms=1, UnitType='MEDIC', UnitSequenceInCallDispatch=2, FirePreventionDistrict=3, SupervisorDistrict=6, Neighborhood='Tenderloin', Location='(37.7811772186856, -122.411699931232)', RowID='020110023-M41', Delay=Decimal('2'), CallDateAsDt=datetime.date(2002, 1, 1)),\n",
       " Row(CallNumber=20110032, UnitID='E11', IncidentNumber='2003250', CallType='Vehicle Fire', CallDate=datetime.datetime(2002, 1, 1, 0, 11), WatchDate=datetime.datetime(2002, 1, 1, 0, 10), CallFinalDisposition='Other', AvailableDtTm='01/11/2002 04:16:46 AM', Address='APPLETON AV/MISSION ST', City='SF', Zipcode='94110', Battalion='B06', StationArea='32', Box='5626', OriginalPriority=3, Priority=3, FinalPriority=3, ALSUnit='false', CallTypeGroup=None, NumAlarms=1, UnitType='ENGINE', UnitSequenceInCallDispatch=1, FirePreventionDistrict=6, SupervisorDistrict=9, Neighborhood='Bernal Heights', Location='(37.7388432849018, -122.423948785199)', RowID='020110032-E11', Delay=Decimal('2'), CallDateAsDt=datetime.date(2002, 1, 1)),\n",
       " Row(CallNumber=20110043, UnitID='B04', IncidentNumber='2003259', CallType='Alarms', CallDate=datetime.datetime(2002, 1, 1, 0, 11), WatchDate=datetime.datetime(2002, 1, 1, 0, 10), CallFinalDisposition='Other', AvailableDtTm='01/11/2002 06:01:58 AM', Address='1400 Block of SUTTER ST', City='SF', Zipcode='94109', Battalion='B04', StationArea='03', Box='3223', OriginalPriority=3, Priority=3, FinalPriority=3, ALSUnit='false', CallTypeGroup=None, NumAlarms=1, UnitType='CHIEF', UnitSequenceInCallDispatch=2, FirePreventionDistrict=4, SupervisorDistrict=2, Neighborhood='Western Addition', Location='(37.7872890372638, -122.424236212664)', RowID='020110043-B04', Delay=Decimal('3'), CallDateAsDt=datetime.date(2002, 1, 1))]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_df = (calls_df.select(\"*\")\n",
    " .withColumn(\"CallDateAsDt\", to_date(col(\"CallDate\"), 'dd/mm/yyyy'))\n",
    " .withColumn(\"CallDate\", to_timestamp(col(\"CallDate\"), \"dd/mm/yyyy\"))\n",
    " .withColumn(\"WatchDate\", to_timestamp(col(\"WatchDate\"), \"dd/mm/yyyy\"))\n",
    "# .distinct()\n",
    ")\n",
    "\n",
    "calls_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations and Actions \n",
    "* Renaming, adding and dropping columns \n",
    "* Aggregations\n",
    "* The Dataset API. (Scala and Java)\n",
    "\n",
    "Now you can use pyspark.sql.functions `.month()`, `year()`, and `day()` to analyse the data further.\n",
    "\n",
    "`.avg()` ,`.min()`, `.max()`, `.sum()`, `.distinct()` for basic Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|year(CallDate)|\n",
      "+--------------+\n",
      "|          2000|\n",
      "|          2001|\n",
      "|          2002|\n",
      "|          2003|\n",
      "|          2004|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(calls_df.select(year(\"CallDate\"))\n",
    ".distinct()\n",
    ".orderBy(year(\"CallDate\"))\n",
    ".show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe API offers the `collect()` method. For extremely large operations this is highly computationally intensive, and lead to OOM exceptions.\n",
    "\n",
    "Unlike `count()` which returns a single number to the driver.\n",
    "\n",
    "`collect()`` returns a collection of all the `Row`` objects in the entire Dataframe object to the driver.\n",
    "\n",
    "Use `take(n)`, which returns the n number of `row objects` back to the driver.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparklearning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
